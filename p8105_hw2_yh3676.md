p8105_hw2_yh3676
================
Yuzhe Hu
2023-10-03

``` r
library(tidyverse)
library(readxl)
```

## Problem 1

Clean `pols-month.csv` data

``` r
pols_month = 
  read_csv("./data/pols-month.csv") |>
  janitor::clean_names() |>
  separate(mon, into = c("year","month","day"), sep = "-") |>
  mutate(month = month.abb[as.numeric(month)],
         president =  ifelse(prez_gop == 1,"gop","dem")) |> 
  select(-prez_dem, -prez_gop, -day)
```

Clean `snp.csv` data

``` r
snp_df = 
  read_csv("./data/snp.csv") |>
  separate(date, into = c("month", "day", "year"), sep = "/") |>
  mutate(month = month.abb[as.numeric(month)]) |>
  mutate(year = ifelse(as.numeric(year) <= 16, paste0("20", year), paste0("19", year))) |>
  select(-day) |>
  select(year, month, everything())
```

Clean `unemployment.csv` data

``` r
unempl_df = 
  read_csv("./data/unemployment.csv") |>
  pivot_longer(Jan:Dec, names_to = "month", values_to = "unemployment rate") |> 
  rename(year = Year) |>
  mutate(year = as.character(year))
```

Merging `snp` into `pols`, and then merging `unemployment` into the
result.

``` r
# Merging `snp_df` into `pols_month`
merge_df_1 =
  left_join(pols_month, snp_df, by = c("year","month"))

# Then merging `unempl_df`:
merge_df = 
  left_join(merge_df_1, unempl_df, by = c("year","month"))
```

- The file`pol_month.csv` contains data on the number of democratic or
  republican national politicians at various points in time between 1947
  and 2015.
- The file `snp.csv` contains data related to Standard & Poor’s stock
  market index from 1950 to 2015.
- The file `unemployment.csv` contains monthly percentage of
  unemployment data from 1948 to 2015. \* The resulting dataset is
  merged by the above three datasets, which comprises 822 observations
  and 11 variables. It covers a 68-year range from 1947 to 2015. Key
  variables in the resulting dataset are
  `year`,`month`,`president`,`close` and `unemployment rate`.

## Problem 2

Clean the *Mr. Trash Wheel* sheet

``` r
mr_wheel = 
  read_excel('./data/202309 Trash Wheel Collection Data.xlsx', sheet = 1, range = 'A2:N586') |>
  janitor::clean_names() |>
  mutate(year = as.numeric(year))
```

The data include a column for the (approximate) number of homes powered.
This calculation is described in the `Homes powered note`, but not
applied to every row in the dataset. Update the data to include a new
`homes_powered` variable based on this calculation.

``` r
mr_wheel = mutate(mr_wheel, homes_powered = weight_tons * 500 / 30)
```

Use a similar process to import, clean, and organize the data for
*Professor Trash Wheel* and *Gwynnda*, and combine these with the
*Mr. Trash Wheel* dataset to produce a single tidy dataset.

``` r
professor_wheel = 
  read_excel('./data/202309 Trash Wheel Collection Data.xlsx', sheet = 2, range = 'A2:M108') |>
  janitor::clean_names() |>
  mutate(homes_powered = weight_tons*500/30) |>
  mutate(type = 'professor trash wheel')

gwynnda_wheel = 
  read_excel('./data/202309 Trash Wheel Collection Data.xlsx', sheet = 4, range = 'A2:L157') |>
  janitor::clean_names() |>
  mutate(homes_powered = weight_tons*500/30) |>
  mutate(type = 'gwynnda trash wheel')

mr_wheel = mutate(mr_wheel, type = 'mr trash wheel')

## Combine the three datasets
Combine_wheel = 
  full_join(mr_wheel, professor_wheel) |> 
  full_join(gwynnda_wheel)
```

- The `Combine_wheel` is a collection of three datasets with 845 number
  of observations. 584 observations from the *Mr. Trash Wheel* dataset,
  106 observations from the *Professor Trash Wheel* dataset, and 155
  observations from the *Gwynnda Trash Wheel* dataset. For key
  variables, each observation contains the date (`month`, `year` and
  `date`), weight(`weight_tons`) and volume(`volume_cubic_yards`) of
  trash, number of different trash categories (e.g. `plastic_bags`,
  `cigarette_butts`), and which trash wheel it belongs to.
- The total weight of trash collected by Professor Trash Wheel is 216.26
  tons.
- The total number of cigarette butts collected by Gwynnda in July of
  2021 is 1.63^{4}.

## Problem 3

Clean the dataset of baseline demographics.

``` r
# import data and skip the first row
baseline_df = read.csv("./data/MCI_baseline.csv", skip = 1) |> 
  janitor::clean_names() |> 
# Change types of `sex` and `apoe4`
  mutate(sex = if_else(sex == 0, 'female', 'male'),
  apoe4 = if_else(apoe4 == 0, 'non-carrier', 'carrier')) |> 
# Remove unqualified observations
  filter(age_at_onset > current_age | age_at_onset == '.')
```

- Important steps in the import process including skipping the first row
  of the dataset, cleaning the variable names into tidy format, changing
  the form of showing variables `sex` and `apoe4`, and removing
  participants who do not meet the stated inclusion criteria.
- 479 participants were recruited (after removing unqualified
  participants), of these 93 developed MCI.
- The average baseline age is 65.0286013.
- 30% of women in the study are APOE4 carriers.

Clean *longitudinally observed biomarker values* dataset

``` r
amyloid_df = 
  read_csv('./data/mci_amyloid.csv', skip = 1) |>
  janitor::clean_names() |>
  pivot_longer(
    baseline:time_8,
    names_to = 'time',
    values_to = 'amyloid_ratio'
  ) |>
  rename(id = study_id) |>
  mutate(amyloid_ratio = as.numeric(amyloid_ratio)) |> 
  mutate(time = case_match(time,
      "baseline" ~ 0,
      "time_2" ~ 2,
      "time_4" ~ 4,
      "time_6" ~ 6,
      "time_8" ~ 8
    ))
```

- The dataset `amyloid_df` is imported by skipping the first row. Use
  `pivot_longer` to transform the dataset from wide to long format. The
  column name `study_id` is changed to `id` to match with the
  `baseline_df` dataset. The data type of `amyloid_ratio` is converted
  to numeric through `mutate`.
- The dateset `amyloid_df` has 2435 observations and 3 variables, with
  variale names: id, time, amyloid_ratio.

Check whether some participants appear in only the baseline or amyloid
datasets.

``` r
##Select the ids first
id_baseline = unique(pull(baseline_df, id))
id_amyloid = unique(pull(amyloid_df, id))
#Ids of participants that only appear in `MCI_baseline.csv`
id_baseline_only = id_baseline[!(id_baseline %in% id_amyloid)]
#Ids of participants that only appear in `mci_amyloid.csv`
id_amyloid_only = id_amyloid[!(id_amyloid %in% id_baseline)] 
```

- A total of 8 participants appear in only the baseline dataset, and
  their id are 14, 49, 92, 179, 268, 304, 389, 412. A total of 16
  participants appear in only the amyloid dataset, and their id are 72,
  234, 283, 380, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,
  495.

Combine the demographic and biomarker datasets so that only participants
who appear in both datasets are retained, and export the result as a
CSV.

``` r
#Combine the data set
combined_df = inner_join(baseline_df, amyloid_df, by = "id")
#Export the combined data
write_csv(combined_df,"./data/combined_df.csv")
```

- The resulting dataset `combined_df` contains the data of 471
  participants who appear in both datasets, including their basic
  demographic information (`id`, `current_age`, `sex`, `education` ),
  APOE4 carrier status (`apoe4`), `age_at_onset` of MCI and their
  amyloid β 42/40 ratio (`amyloid_ratio`) at measurement time (`time`).

- 142 of the participants are APOE4 carriers, and 59 of them
  developed MCI. 329 of the participants are non-carriers, and 31 of
  them developed MCI.
